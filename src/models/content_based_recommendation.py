"""
åŸºäºå†…å®¹çš„æ¨èç³»ç»Ÿ
åˆ©ç”¨å•†å“ç‰¹å¾ï¼ˆç±»åˆ«ã€å“ç‰Œã€ä»·æ ¼ç­‰ï¼‰è®¡ç®—å•†å“ç›¸ä¼¼åº¦ï¼Œç”Ÿæˆæ¨è
"""
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler, LabelEncoder
import pickle
import json
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

class ContentBasedRecommender:
    def __init__(self, data_dir="data"):
        self.data_dir = data_dir
        self.ratings_df = None
        self.metadata_df = None
        self.item_features = None
        self.item_similarity_matrix = None
        self.tfidf_vectorizer = None
        self.scaler = StandardScaler()
        
    def load_data(self):
        """åŠ è½½æ•°æ®"""
        print("ğŸ“‚ åŠ è½½æ•°æ®...")
        
        # åŠ è½½è¯„åˆ†æ•°æ®
        self.ratings_df = pd.read_csv(f"{self.data_dir}/processed_ratings.csv")
        
        # åŠ è½½å•†å“å…ƒæ•°æ®
        self.load_metadata()
        
        print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ:")
        print(f"   - è¯„åˆ†æ•°æ®: {len(self.ratings_df):,} æ¡")
        print(f"   - å•†å“å…ƒæ•°æ®: {len(self.metadata_df):,} ä¸ª")
        
    def load_metadata(self):
        """åŠ è½½å¹¶å¤„ç†å•†å“å…ƒæ•°æ®"""
        metadata_file = f"{self.data_dir}/meta_Electronics.json"
        metadata_list = []
        
        with open(metadata_file, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    item = eval(line.strip())
                    
                    # æå–ä¸»è¦ç±»åˆ«
                    main_category = ""
                    sub_category = ""
                    if item.get('categories'):
                        cats = item['categories'][0] if item['categories'] else []
                        if isinstance(cats, list) and len(cats) > 0:
                            main_category = cats[0] if len(cats) > 0 else ""
                            sub_category = cats[1] if len(cats) > 1 else ""
                    
                    metadata_list.append({
                        'item_id': item.get('asin', ''),
                        'title': item.get('title', ''),
                        'main_category': main_category,
                        'sub_category': sub_category,
                        'price': item.get('price', 0),
                        'brand': item.get('brand', ''),
                        'description': item.get('description', '')
                    })
                except:
                    continue
        
        self.metadata_df = pd.DataFrame(metadata_list)
        
        # åªä¿ç•™æœ‰è¯„åˆ†çš„å•†å“
        rated_items = set(self.ratings_df['item_id'].unique())
        self.metadata_df = self.metadata_df[self.metadata_df['item_id'].isin(rated_items)]
        
        print(f"   - æœ‰æ•ˆå•†å“å…ƒæ•°æ®: {len(self.metadata_df):,} ä¸ª")
        
    def create_item_features(self):
        """åˆ›å»ºå•†å“ç‰¹å¾çŸ©é˜µ"""
        print("ğŸ”§ åˆ›å»ºå•†å“ç‰¹å¾çŸ©é˜µ...")
        
        # å¤„ç†ç¼ºå¤±å€¼
        self.metadata_df['price'] = self.metadata_df['price'].fillna(0)
        self.metadata_df['brand'] = self.metadata_df['brand'].fillna('Unknown')
        self.metadata_df['main_category'] = self.metadata_df['main_category'].fillna('Unknown')
        self.metadata_df['sub_category'] = self.metadata_df['sub_category'].fillna('Unknown')
        self.metadata_df['description'] = self.metadata_df['description'].fillna('')
        
        # 1. ç±»åˆ«ç‰¹å¾ (One-hotç¼–ç )
        category_features = pd.get_dummies(self.metadata_df['main_category'], prefix='main_cat')
        sub_category_features = pd.get_dummies(self.metadata_df['sub_category'], prefix='sub_cat')
        
        # 2. å“ç‰Œç‰¹å¾ (One-hotç¼–ç ï¼Œåªä¿ç•™å‡ºç°é¢‘ç‡è¾ƒé«˜çš„å“ç‰Œ)
        brand_counts = self.metadata_df['brand'].value_counts()
        top_brands = brand_counts[brand_counts >= 10].index  # è‡³å°‘å‡ºç°10æ¬¡çš„å“ç‰Œ
        self.metadata_df['brand_grouped'] = self.metadata_df['brand'].apply(
            lambda x: x if x in top_brands else 'Other'
        )
        brand_features = pd.get_dummies(self.metadata_df['brand_grouped'], prefix='brand')
        
        # 3. ä»·æ ¼ç‰¹å¾ (æ ‡å‡†åŒ–)
        price_features = self.metadata_df[['price']].copy()
        price_features['price_normalized'] = self.scaler.fit_transform(price_features[['price']])
        
        # 4. ä»·æ ¼åŒºé—´ç‰¹å¾
        price_features['price_range'] = pd.cut(
            self.metadata_df['price'], 
            bins=[0, 20, 50, 100, 200, 500, float('inf')],
            labels=['0-20', '20-50', '50-100', '100-200', '200-500', '500+']
        )
        price_range_features = pd.get_dummies(price_features['price_range'], prefix='price_range')
        
        # 5. æ–‡æœ¬ç‰¹å¾ (TF-IDF)
        # åˆå¹¶æ ‡é¢˜å’Œæè¿°
        text_content = (self.metadata_df['title'] + ' ' + self.metadata_df['description']).fillna('')
        
        # ä½¿ç”¨TF-IDFå‘é‡åŒ–
        self.tfidf_vectorizer = TfidfVectorizer(
            max_features=1000,  # é™åˆ¶ç‰¹å¾æ•°é‡
            stop_words='english',
            ngram_range=(1, 2),  # ä½¿ç”¨1-gramå’Œ2-gram
            min_df=2,  # è‡³å°‘å‡ºç°åœ¨2ä¸ªæ–‡æ¡£ä¸­
            max_df=0.8  # æœ€å¤šå‡ºç°åœ¨80%çš„æ–‡æ¡£ä¸­
        )
        
        text_features = self.tfidf_vectorizer.fit_transform(text_content)
        text_features_df = pd.DataFrame(
            text_features.toarray(), 
            columns=[f'text_{i}' for i in range(text_features.shape[1])]
        )
        
        # åˆå¹¶æ‰€æœ‰ç‰¹å¾
        self.item_features = pd.concat([
            self.metadata_df[['item_id']].reset_index(drop=True),
            category_features.reset_index(drop=True),
            sub_category_features.reset_index(drop=True),
            brand_features.reset_index(drop=True),
            price_features[['price_normalized']].reset_index(drop=True),
            price_range_features.reset_index(drop=True),
            text_features_df.reset_index(drop=True)
        ], axis=1)
        
        print(f"   - ç‰¹å¾çŸ©é˜µç»´åº¦: {self.item_features.shape}")
        print(f"   - ç±»åˆ«ç‰¹å¾: {len(category_features.columns)}")
        print(f"   - å­ç±»åˆ«ç‰¹å¾: {len(sub_category_features.columns)}")
        print(f"   - å“ç‰Œç‰¹å¾: {len(brand_features.columns)}")
        print(f"   - æ–‡æœ¬ç‰¹å¾: {text_features.shape[1]}")
        
    def compute_item_similarity(self):
        """è®¡ç®—å•†å“ç›¸ä¼¼åº¦çŸ©é˜µï¼ˆä¼˜åŒ–å†…å­˜ä½¿ç”¨ï¼‰"""
        print("ğŸ“Š å‡†å¤‡ç‰¹å¾çŸ©é˜µï¼ˆä¸é¢„è®¡ç®—å®Œæ•´ç›¸ä¼¼åº¦çŸ©é˜µä»¥èŠ‚çœå†…å­˜ï¼‰...")

        # æå–ç‰¹å¾çŸ©é˜µï¼ˆé™¤äº†item_idåˆ—ï¼‰
        feature_columns = [col for col in self.item_features.columns if col != 'item_id']
        self.feature_matrix = self.item_features[feature_columns].values

        # æ ‡å‡†åŒ–ç‰¹å¾çŸ©é˜µä»¥ä¾¿è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        from sklearn.preprocessing import normalize
        self.feature_matrix = normalize(self.feature_matrix, norm='l2')

        print(f"   - ç‰¹å¾çŸ©é˜µç»´åº¦: {self.feature_matrix.shape}")
        print("   - ä½¿ç”¨æŒ‰éœ€è®¡ç®—ç›¸ä¼¼åº¦çš„æ–¹å¼ä»¥èŠ‚çœå†…å­˜")
        
    def get_user_profile(self, user_id):
        """æ„å»ºç”¨æˆ·åå¥½æ¡£æ¡ˆ"""
        # è·å–ç”¨æˆ·è¯„åˆ†å†å²
        user_ratings = self.ratings_df[self.ratings_df['user_id'] == user_id]
        
        # åªè€ƒè™‘é«˜è¯„åˆ†å•†å“ï¼ˆ4æ˜ŸåŠä»¥ä¸Šï¼‰
        high_rated_items = user_ratings[user_ratings['rating'] >= 4]['item_id'].tolist()
        
        # è·å–è¿™äº›å•†å“çš„ç‰¹å¾
        user_item_features = self.item_features[
            self.item_features['item_id'].isin(high_rated_items)
        ]
        
        if len(user_item_features) == 0:
            return None
        
        # è®¡ç®—ç”¨æˆ·åå¥½å‘é‡ï¼ˆå¹³å‡ç‰¹å¾å‘é‡ï¼‰
        feature_columns = [col for col in self.item_features.columns if col != 'item_id']
        user_profile = user_item_features[feature_columns].mean().values
        
        return user_profile, high_rated_items
    
    def get_content_recommendations(self, user_id, n_recommendations=10):
        """ä¸ºç”¨æˆ·ç”ŸæˆåŸºäºå†…å®¹çš„æ¨è"""
        print(f"ğŸ¯ ä¸ºç”¨æˆ· {user_id} ç”ŸæˆåŸºäºå†…å®¹çš„æ¨è...")
        
        # æ„å»ºç”¨æˆ·åå¥½æ¡£æ¡ˆ
        user_profile_result = self.get_user_profile(user_id)
        if user_profile_result is None:
            print("   - ç”¨æˆ·æ²¡æœ‰è¶³å¤Ÿçš„é«˜è¯„åˆ†å†å²ï¼Œæ— æ³•ç”Ÿæˆæ¨è")
            return []
        
        user_profile, user_items = user_profile_result
        
        # è·å–ç”¨æˆ·å·²è¯„åˆ†çš„æ‰€æœ‰å•†å“
        user_rated_items = set(self.ratings_df[self.ratings_df['user_id'] == user_id]['item_id'])
        
        # è®¡ç®—ç”¨æˆ·åå¥½ä¸æ‰€æœ‰å•†å“çš„ç›¸ä¼¼åº¦
        feature_columns = [col for col in self.item_features.columns if col != 'item_id']
        item_features_matrix = self.item_features[feature_columns].values
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = cosine_similarity([user_profile], item_features_matrix)[0]
        
        # åˆ›å»ºæ¨èåˆ—è¡¨
        recommendations = []
        for idx, similarity in enumerate(similarities):
            item_id = self.item_features.iloc[idx]['item_id']
            
            # æ’é™¤ç”¨æˆ·å·²è¯„åˆ†çš„å•†å“
            if item_id not in user_rated_items:
                recommendations.append((item_id, similarity))
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        recommendations.sort(key=lambda x: x[1], reverse=True)
        
        # æ·»åŠ å•†å“ä¿¡æ¯
        final_recommendations = []
        for item_id, similarity in recommendations[:n_recommendations]:
            item_info = self.metadata_df[self.metadata_df['item_id'] == item_id]
            if not item_info.empty:
                item_info = item_info.iloc[0]
                final_recommendations.append({
                    'item_id': item_id,
                    'similarity_score': round(similarity, 4),
                    'title': item_info['title'],
                    'main_category': item_info['main_category'],
                    'sub_category': item_info['sub_category'],
                    'price': item_info['price'],
                    'brand': item_info['brand']
                })
        
        return final_recommendations
    
    def get_similar_items(self, item_id, n_similar=10):
        """è·å–ä¸æŒ‡å®šå•†å“ç›¸ä¼¼çš„å•†å“ï¼ˆæŒ‰éœ€è®¡ç®—ç›¸ä¼¼åº¦ï¼‰"""
        try:
            # æ‰¾åˆ°å•†å“åœ¨ç‰¹å¾çŸ©é˜µä¸­çš„ç´¢å¼•
            item_idx = self.item_features[self.item_features['item_id'] == item_id].index[0]

            # è·å–è¯¥å•†å“çš„ç‰¹å¾å‘é‡
            item_vector = self.feature_matrix[item_idx:item_idx+1]

            # è®¡ç®—ä¸æ‰€æœ‰å•†å“çš„ç›¸ä¼¼åº¦
            similarities = np.dot(self.feature_matrix, item_vector.T).flatten()

            # è·å–æœ€ç›¸ä¼¼çš„å•†å“ï¼ˆæ’é™¤è‡ªå·±ï¼‰
            similar_indices = np.argsort(similarities)[::-1][1:n_similar+1]

            similar_items = []
            for idx in similar_indices:
                similar_item_id = self.item_features.iloc[idx]['item_id']
                item_info = self.metadata_df[self.metadata_df['item_id'] == similar_item_id]
                if not item_info.empty:
                    item_info = item_info.iloc[0]
                    similar_items.append({
                        'item_id': similar_item_id,
                        'similarity_score': round(similarities[idx], 4),
                        'title': item_info['title'],
                        'main_category': item_info['main_category'],
                        'price': item_info['price'],
                        'brand': item_info['brand']
                    })

            return similar_items
        except:
            return []
    
    def save_model(self):
        """ä¿å­˜æ¨¡å‹"""
        print("ğŸ’¾ ä¿å­˜åŸºäºå†…å®¹çš„æ¨èæ¨¡å‹...")
        
        # ä¿å­˜ç‰¹å¾çŸ©é˜µ
        self.item_features.to_csv(f"{self.data_dir}/item_features.csv", index=False)
        
        # ä¿å­˜ç‰¹å¾çŸ©é˜µ
        np.save(f"{self.data_dir}/feature_matrix.npy", self.feature_matrix)
        
        # ä¿å­˜TF-IDFå‘é‡åŒ–å™¨
        with open(f"{self.data_dir}/tfidf_vectorizer.pkl", 'wb') as f:
            pickle.dump(self.tfidf_vectorizer, f)
        
        # ä¿å­˜æ ‡å‡†åŒ–å™¨
        with open(f"{self.data_dir}/price_scaler.pkl", 'wb') as f:
            pickle.dump(self.scaler, f)
        
        print("âœ… æ¨¡å‹ä¿å­˜å®Œæˆ!")
    
    def run_content_based_recommendation(self):
        """è¿è¡Œå®Œæ•´çš„åŸºäºå†…å®¹çš„æ¨èæµç¨‹"""
        print("ğŸš€ å¼€å§‹åŸºäºå†…å®¹çš„æ¨èç³»ç»Ÿè®­ç»ƒ...\n")
        
        self.load_data()
        self.create_item_features()
        self.compute_item_similarity()
        self.save_model()
        
        print(f"\nğŸ‰ åŸºäºå†…å®¹çš„æ¨èç³»ç»Ÿæ„å»ºå®Œæˆ!")
        return self

# æ³¨é‡Šæ‰æµ‹è¯•ä»£ç ï¼Œé¿å…åœ¨å¯¼å…¥æ—¶æ‰§è¡Œ
# if __name__ == "__main__":
#     cb_recommender = ContentBasedRecommender()
#     model = cb_recommender.run_content_based_recommendation()
