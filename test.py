"""
æ¨èç³»ç»ŸåŠŸèƒ½å®Œæ•´æ€§æµ‹è¯•
æµ‹è¯•æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""
import sys
import os
import pandas as pd
import numpy as np
import pickle

def test_data_integrity():
    """æµ‹è¯•æ•°æ®å®Œæ•´æ€§"""
    print("ğŸ“Š æµ‹è¯•æ•°æ®å®Œæ•´æ€§...")
    
    try:
        # æµ‹è¯•è¯„åˆ†æ•°æ®
        ratings_df = pd.read_csv('data/processed_ratings.csv')
        print(f"âœ… è¯„åˆ†æ•°æ®: {len(ratings_df):,} æ¡")
        print(f"   - ç”¨æˆ·æ•°: {ratings_df['user_id'].nunique():,}")
        print(f"   - å•†å“æ•°: {ratings_df['item_id'].nunique():,}")
        print(f"   - è¯„åˆ†èŒƒå›´: {ratings_df['rating'].min()}-{ratings_df['rating'].max()}")
        
        # æµ‹è¯•ç‰¹å¾æ•°æ®
        item_features = pd.read_csv('data/item_features.csv')
        feature_matrix = np.load('data/feature_matrix.npy')
        print(f"âœ… ç‰¹å¾æ•°æ®: {feature_matrix.shape[0]:,} Ã— {feature_matrix.shape[1]:,}")
        
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®å®Œæ•´æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_collaborative_filtering():
    """æµ‹è¯•ååŒè¿‡æ»¤åŠŸèƒ½"""
    print("\nğŸ¤– æµ‹è¯•ååŒè¿‡æ»¤åŠŸèƒ½...")
    
    try:
        # åŠ è½½SVDæ¨¡å‹
        with open('data/svd_model.pkl', 'rb') as f:
            svd_model = pickle.load(f)
        
        # åŠ è½½æ•°æ®
        ratings_df = pd.read_csv('data/processed_ratings.csv')
        
        # é€‰æ‹©æµ‹è¯•ç”¨æˆ·
        user_activity = ratings_df['user_id'].value_counts()
        test_user = user_activity.index[0]
        
        # ç”Ÿæˆæ¨è
        user_items = set(ratings_df[ratings_df['user_id'] == test_user]['item_id'])
        all_items = ratings_df['item_id'].unique()
        test_items = [item for item in all_items if item not in user_items][:5]
        
        predictions = []
        for item_id in test_items:
            pred = svd_model.predict(test_user, item_id)
            predictions.append((item_id, pred.est))
        
        print(f"âœ… ååŒè¿‡æ»¤æ¨è: {len(predictions)} ä¸ª")
        print(f"   - æµ‹è¯•ç”¨æˆ·: {test_user}")
        print(f"   - é¢„æµ‹è¯„åˆ†èŒƒå›´: {min(p[1] for p in predictions):.2f}-{max(p[1] for p in predictions):.2f}")
        
        return True
    except Exception as e:
        print(f"âŒ ååŒè¿‡æ»¤æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_content_based():
    """æµ‹è¯•åŸºäºå†…å®¹æ¨èåŠŸèƒ½"""
    print("\nğŸ“‹ æµ‹è¯•åŸºäºå†…å®¹æ¨èåŠŸèƒ½...")
    
    try:
        # åŠ è½½ç‰¹å¾æ•°æ®
        feature_matrix = np.load('data/feature_matrix.npy')
        item_features = pd.read_csv('data/item_features.csv')
        ratings_df = pd.read_csv('data/processed_ratings.csv')
        
        # é€‰æ‹©æµ‹è¯•ç”¨æˆ·
        user_activity = ratings_df['user_id'].value_counts()
        test_user = user_activity.index[0]
        
        # è·å–ç”¨æˆ·é«˜è¯„åˆ†å•†å“
        user_ratings = ratings_df[ratings_df['user_id'] == test_user]
        high_rated_items = user_ratings[user_ratings['rating'] >= 4]['item_id'].tolist()
        
        if high_rated_items:
            # æ„å»ºç”¨æˆ·åå¥½æ¡£æ¡ˆ
            user_item_indices = []
            for item_id in high_rated_items[:5]:
                item_idx = item_features[item_features['item_id'] == item_id].index
                if len(item_idx) > 0:
                    user_item_indices.append(item_idx[0])
            
            if user_item_indices:
                user_profile = feature_matrix[user_item_indices].mean(axis=0)
                
                # è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆé™åˆ¶è®¡ç®—é‡ï¼‰
                similarities = np.dot(feature_matrix[:100], user_profile)
                
                print(f"âœ… åŸºäºå†…å®¹æ¨è: è®¡ç®—å®Œæˆ")
                print(f"   - ç”¨æˆ·é«˜è¯„åˆ†å•†å“: {len(high_rated_items)}")
                print(f"   - ç›¸ä¼¼åº¦èŒƒå›´: {similarities.min():.3f}-{similarities.max():.3f}")
                
                return True
        
        print("âš ï¸ ç”¨æˆ·æ²¡æœ‰è¶³å¤Ÿçš„é«˜è¯„åˆ†å†å²")
        return True
        
    except Exception as e:
        print(f"âŒ åŸºäºå†…å®¹æ¨èæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_hybrid_system():
    """æµ‹è¯•æ··åˆæ¨èç³»ç»Ÿ"""
    print("\nğŸ”„ æµ‹è¯•æ··åˆæ¨èç³»ç»Ÿ...")
    
    try:
        sys.path.append('src/models')
        from hybrid_recommendation import HybridRecommendationSystem
        
        # åˆå§‹åŒ–ç³»ç»Ÿ
        hybrid_system = HybridRecommendationSystem('data')
        hybrid_system.load_models()
        
        # é€‰æ‹©æµ‹è¯•ç”¨æˆ·
        user_activity = hybrid_system.ratings_df['user_id'].value_counts()
        test_user = user_activity.index[0]
        
        # ç”Ÿæˆæ¨è
        recommendations = hybrid_system.get_hybrid_recommendations(test_user, 'weighted', 2)
        
        print(f"âœ… æ··åˆæ¨èç³»ç»Ÿ: {len(recommendations)} ä¸ªæ¨è")
        print(f"   - æµ‹è¯•ç”¨æˆ·: {test_user}")
        
        for i, rec in enumerate(recommendations, 1):
            print(f"   {i}. å•†å“: {rec['item_id']} | è¯„åˆ†: {rec['hybrid_score']:.3f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ··åˆæ¨èç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_model_files():
    """æµ‹è¯•æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§"""
    print("\nğŸ“ æµ‹è¯•æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§...")
    
    required_files = [
        'data/processed_ratings.csv',
        'data/meta_Electronics.json',
        'data/svd_model.pkl',
        'data/feature_matrix.npy',
        'data/item_features.csv',
        'data/tfidf_vectorizer.pkl',
        'data/price_scaler.pkl'
    ]
    
    missing_files = []
    for file in required_files:
        if os.path.exists(file):
            size_mb = os.path.getsize(file) / (1024*1024)
            print(f"   âœ… {file} ({size_mb:.1f} MB)")
        else:
            print(f"   âŒ {file} - ç¼ºå¤±")
            missing_files.append(file)
    
    if missing_files:
        print(f"âŒ ç¼ºå¤± {len(missing_files)} ä¸ªæ–‡ä»¶")
        return False
    else:
        print("âœ… æ‰€æœ‰æ¨¡å‹æ–‡ä»¶å®Œæ•´")
        return True

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("ğŸ§ª æ¨èç³»ç»ŸåŠŸèƒ½å®Œæ•´æ€§æµ‹è¯•")
    print("=" * 50)
    
    tests = [
        ("æ•°æ®å®Œæ•´æ€§", test_data_integrity),
        ("ååŒè¿‡æ»¤", test_collaborative_filtering),
        ("åŸºäºå†…å®¹æ¨è", test_content_based),
        ("æ··åˆæ¨èç³»ç»Ÿ", test_hybrid_system),
        ("æ¨¡å‹æ–‡ä»¶", test_model_files)
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âŒ {test_name}æµ‹è¯•å¼‚å¸¸: {e}")
            results.append((test_name, False))
    
    # æµ‹è¯•ç»“æœæ±‡æ€»
    print("\n" + "=" * 50)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 50)
    
    passed = 0
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»ä½“ç»“æœ: {passed}/{len(results)} é¡¹æµ‹è¯•é€šè¿‡")
    
    if passed == len(results):
        print("ğŸ‰ æ‰€æœ‰åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼æ¨èç³»ç»Ÿå®Œå…¨æ­£å¸¸ï¼")
    else:
        print("âš ï¸ éƒ¨åˆ†åŠŸèƒ½å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥å¤±è´¥çš„æµ‹è¯•é¡¹")

if __name__ == "__main__":
    main()
